{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Paths\n",
    "data_dir = os.environ.get('DATA_DIR',\n",
    "                          '/gpfs/home/zh283/StockPredictionDNN/Data')\n",
    "parquet_dir = os.path.join(data_dir, 'parquet')\n",
    "factor_xlsx = os.path.join(data_dir, 'factors_list.xlsx')\n",
    "tfrecord_dir = os.path.join(data_dir, 'tfrecords')\n",
    "\n",
    "# Clean out old TFRecords\n",
    "if os.path.exists(tfrecord_dir):\n",
    "    shutil.rmtree(tfrecord_dir)\n",
    "os.makedirs(tfrecord_dir, exist_ok=True)\n",
    "\n",
    "# Load characteristic list to define feature columns\n",
    "chars = pd.read_excel(factor_xlsx)\n",
    "FEATURE_COLS = chars.loc[chars['abr_jkp'].notna(), 'abr_jkp'].tolist()\n",
    "\n",
    "# Other columns\n",
    "META_COLS = [\n",
    "    'permno', 'eom', 'me', 'size_grp', 'crsp_exchcd', 'ret', 'ret_exc'\n",
    "]\n",
    "WEIGHT_COLS = ['w_ew', 'w_vw']\n",
    "LABEL_COLS = ['ret_exc_lead1m', 'ret_pct', 'ret_z', 'ret_invn']\n",
    "\n",
    "\n",
    "# Helper for features\n",
    "def _bytes_feature(v):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[v]))\n",
    "\n",
    "\n",
    "def _float_feature(v):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=v))\n",
    "\n",
    "\n",
    "def _int64_feature(v):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=v))\n",
    "\n",
    "\n",
    "def serialize_example(rec):\n",
    "    feat = {}\n",
    "    # feature vector\n",
    "    arr = rec['feat'] if 'feat' in rec else [rec[c] for c in FEATURE_COLS]\n",
    "    feat['feat'] = _float_feature(arr)\n",
    "    # weights, meta, label\n",
    "    for c in WEIGHT_COLS + META_COLS + LABEL_COLS:\n",
    "        val = rec[c]\n",
    "        if isinstance(val, int): feat[c] = _int64_feature([val])\n",
    "        else: feat[c] = _float_feature([float(val)])\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feat))\n",
    "    return example.SerializeToString()\n",
    "\n",
    "\n",
    "def process_parquet_shard(args):\n",
    "    parquet_file, variant, tfrecord_dir = args\n",
    "    # derive a nice shard name from the filename\n",
    "    fname = os.path.splitext(os.path.basename(parquet_file))[0]\n",
    "    out_path = os.path.join(tfrecord_dir, f\"{variant}-{fname}.tfrecord\")\n",
    "    writer = tf.io.TFRecordWriter(out_path)\n",
    "\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    for _, row in df.iterrows():\n",
    "        writer.write(serialize_example(row.to_dict()))\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    variants = ['raw', 'pct', 'z', 'invn']\n",
    "    tasks = []\n",
    "    for variant in variants:\n",
    "        pattern = os.path.join(parquet_dir, variant, 'year=*', '*.parquet')\n",
    "        for parquet_file in glob.glob(pattern, recursive=True):\n",
    "            tasks.append((parquet_file, variant, tfrecord_dir))\n",
    "\n",
    "    # spin up one worker per core\n",
    "    with Pool() as pool:\n",
    "        pool.map(process_parquet_shard, tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
