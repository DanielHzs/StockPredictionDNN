{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade315cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T22:28:57.630851Z",
     "start_time": "2025-05-08T22:28:52.869356Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746743334.522950  687968 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746743334.529407  687968 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746743334.681445  687968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746743334.681473  687968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746743334.681475  687968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746743334.681477  687968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %% Imports & Config\n",
    "import os\n",
    "import logging\n",
    "# Suppress TensorFlow and absl logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import absl.logging as _absl\n",
    "_absl.set_verbosity('error')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# Set TensorFlow logger level\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "import train_ensemble\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a99f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T22:29:51.160778Z",
     "start_time": "2025-05-08T22:28:57.632410Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746743338.058769  687968 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44326 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:25:00.0, compute capability: 7.5\n",
      "I0000 00:00:1746743338.062571  687968 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 44326 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:81:00.0, compute capability: 7.5\n",
      "I0000 00:00:1746743338.063248  687968 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 44326 MB memory:  -> device: 2, name: Quadro RTX 8000, pci bus id: 0000:e2:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Allow TF to pick GPU if available, otherwise CPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "CONFIG = train_ensemble.CONFIG\n",
    "make_dataset = train_ensemble.make_dataset\n",
    "\n",
    "# %% Phase 0: Prepare output directory\n",
    "pred_dir = Path(\"predictions\")\n",
    "pred_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# %% Phase 1: Preload feature pipelines & build truth DataFrames\n",
    "variants = ['raw', 'pct', 'z', 'invn']\n",
    "ds_feat = {}\n",
    "truth_dfs = {}\n",
    "\n",
    "for var in variants:\n",
    "    # update CONFIG for this variant\n",
    "    CONFIG['variant'] = var\n",
    "    CONFIG['label'] = 'ret_exc_lead1m'\n",
    "    CONFIG['weight'] = 'w_vw'\n",
    "    CONFIG['tfrecord_dir'] = os.path.join(CONFIG['data_dir'], 'tfrecords', var)\n",
    "\n",
    "    # dataset for predictions (features only)\n",
    "    ds = make_dataset(CONFIG['predict_years'], mode='predict')\n",
    "    ds_feat[var] = ds.map(lambda feats, *_: feats).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # extract arrays and meta\n",
    "    records = []\n",
    "    for feats, y, w, meta in ds:\n",
    "        y_arr = y.numpy().ravel()\n",
    "        w_arr = w.numpy().ravel()\n",
    "        # meta is a dict of arrays; convert each to ravel\n",
    "        flat_meta = {k: v.numpy().ravel() for k, v in meta.items()}\n",
    "        # build DataFrame for this batch\n",
    "        batch_df = pd.DataFrame(flat_meta)\n",
    "        batch_df[CONFIG['label']] = y_arr\n",
    "        batch_df['w'] = w_arr\n",
    "        records.append(batch_df)\n",
    "    # concatenate all batches into a single truth DataFrame\n",
    "    truth_dfs[var] = pd.concat(records, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c655d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T22:29:51.167934Z",
     "start_time": "2025-05-08T22:29:51.163327Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# %% Phase 2: Build combo list with GPU assignment\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "num_gpus = len(gpus)\n",
    "combos = []\n",
    "base = Path(CONFIG['model_dir'])\n",
    "for idx, var in enumerate(variants):\n",
    "    for lbl in ['ret_exc_lead1m', 'ret_pct', 'ret_z', 'ret_invn']:\n",
    "        for wt in ['w_ew', 'w_vw']:\n",
    "            for loss in ['mse', 'mae']:\n",
    "                combo = f\"{var}_{lbl}_{wt}_{loss}\"\n",
    "                path = base / combo\n",
    "                if path.is_dir():\n",
    "                    gpu_id = idx % num_gpus if num_gpus > 0 else None\n",
    "                    combos.append((combo, var, lbl, wt, loss, path, gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6496eeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T22:55:23.455706Z",
     "start_time": "2025-05-08T22:51:39.576836Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] dataset for raw_ret_exc_lead1m_w_ew_mae already exists\n",
      "[SKIP] dataset for raw_ret_pct_w_ew_mse already exists\n",
      "[SKIP] dataset for raw_ret_exc_lead1m_w_vw_mae already exists\n",
      "[SKIP] dataset for raw_ret_pct_w_vw_mse already exists\n",
      "[SKIP] dataset for raw_ret_pct_w_ew_mae already exists\n",
      "[SKIP] dataset for raw_ret_z_w_ew_mae already exists\n",
      "[SKIP] dataset for raw_ret_z_w_vw_mae already exists\n",
      "[SKIP] dataset for raw_ret_z_w_vw_mse already exists\n",
      "[SKIP] dataset for raw_ret_invn_w_ew_mae already exists\n",
      "[SKIP] dataset for raw_ret_invn_w_ew_mse already exists\n",
      "[SKIP] dataset for raw_ret_invn_w_vw_mae already exists\n",
      "[SKIP] dataset for raw_ret_invn_w_vw_mse already exists\n",
      "[SKIP] dataset for pct_ret_exc_lead1m_w_vw_mse already exists\n",
      "[SKIP] dataset for pct_ret_exc_lead1m_w_vw_mae already exists\n",
      "[SKIP] dataset for pct_ret_pct_w_ew_mse already exists\n",
      "[SKIP] dataset for pct_ret_exc_lead1m_w_ew_mae already exists\n",
      "[SKIP] dataset for pct_ret_pct_w_ew_mae already exists\n",
      "[SKIP] dataset for pct_ret_pct_w_vw_mse already exists\n",
      "[SKIP] dataset for pct_ret_z_w_ew_mse already exists\n",
      "[SKIP] dataset for pct_ret_z_w_vw_mse already exists\n",
      "[SKIP] dataset for pct_ret_z_w_vw_mae already exists\n",
      "[SKIP] dataset for pct_ret_z_w_ew_mae already exists\n",
      "[SKIP] dataset for pct_ret_invn_w_vw_mse already exists\n",
      "[SKIP] dataset for pct_ret_invn_w_vw_mae already exists\n",
      "[SKIP] dataset for pct_ret_invn_w_ew_mae already exists\n",
      "[SKIP] dataset for z_ret_exc_lead1m_w_vw_mse already exists\n",
      "[SKIP] dataset for z_ret_exc_lead1m_w_ew_mae already exists\n",
      "[SKIP] dataset for z_ret_exc_lead1m_w_vw_mae already exists\n",
      "[SKIP] dataset for z_ret_pct_w_ew_mae already exists\n",
      "[SKIP] dataset for z_ret_pct_w_vw_mae already exists\n",
      "[SKIP] dataset for z_ret_pct_w_ew_mse already exists\n",
      "[SKIP] dataset for z_ret_pct_w_vw_mse already exists\n",
      "[SKIP] dataset for z_ret_z_w_ew_mae already exists\n",
      "[SKIP] dataset for z_ret_invn_w_ew_mse already exists\n",
      "[SKIP] dataset for z_ret_z_w_vw_mse already exists\n",
      "[SKIP] dataset for z_ret_invn_w_ew_mae already exists\n",
      "[SKIP] dataset for z_ret_invn_w_vw_mae already exists\n",
      "[SKIP] dataset for invn_ret_exc_lead1m_w_ew_mse already exists\n",
      "[SKIP] dataset for invn_ret_exc_lead1m_w_vw_mse already exists\n",
      "[SKIP] dataset for invn_ret_exc_lead1m_w_vw_mae already exists\n",
      "[SKIP] dataset for invn_ret_exc_lead1m_w_ew_mae already exists\n",
      "[SKIP] dataset for invn_ret_pct_w_ew_mse already exists\n",
      "[SKIP] dataset for invn_ret_pct_w_ew_mae already exists\n",
      "[SKIP] dataset for invn_ret_pct_w_vw_mae already exists\n",
      "[SKIP] dataset for invn_ret_z_w_ew_mse already exists\n",
      "[SKIP] dataset for invn_ret_pct_w_vw_mse already exists\n",
      "[SKIP] dataset for invn_ret_z_w_vw_mae already exists\n",
      "[SKIP] dataset for invn_ret_invn_w_ew_mse already exists\n",
      "[SKIP] dataset for invn_ret_invn_w_vw_mse already exists\n",
      "[SKIP] dataset for invn_ret_invn_w_vw_mae already exists\n",
      "[SKIP] dataset for invn_ret_z_w_ew_mae already exists\n",
      "[SKIP] dataset for invn_ret_z_w_vw_mse already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/64 [00:00<?, ?combo/s]/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:   0%|          | 0/64 [03:22<?, ?combo/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for raw_ret_exc_lead1m_w_vw_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 53/64 [03:24<00:42,  3.87s/combo]/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  83%|████████▎ | 53/64 [03:29<00:42,  3.87s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for z_ret_z_w_vw_mae saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 54/64 [03:30<00:39,  3.91s/combo]/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  84%|████████▍ | 54/64 [03:31<00:39,  3.91s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for pct_ret_pct_w_vw_mae saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  86%|████████▌ | 55/64 [03:31<00:34,  3.81s/combo]/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  86%|████████▌ | 55/64 [03:31<00:34,  3.81s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for pct_ret_invn_w_ew_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 57/64 [03:32<00:23,  3.42s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for raw_ret_exc_lead1m_w_ew_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  89%|████████▉ | 57/64 [03:32<00:23,  3.42s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for raw_ret_z_w_ew_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  91%|█████████ | 58/64 [03:33<00:19,  3.20s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for z_ret_exc_lead1m_w_ew_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 59/64 [03:33<00:14,  2.91s/combo]/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  92%|█████████▏| 59/64 [03:34<00:14,  2.91s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for raw_ret_pct_w_vw_mae saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 60/64 [03:34<00:10,  2.70s/combo]/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  94%|█████████▍| 60/64 [03:35<00:10,  2.70s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for pct_ret_exc_lead1m_w_ew_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 61/64 [03:35<00:07,  2.40s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for invn_ret_invn_w_ew_mae saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  95%|█████████▌| 61/64 [03:39<00:07,  2.40s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for z_ret_z_w_ew_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 63/64 [03:39<00:02,  2.20s/combo]/gpfs/home/zh283/.conda/envs/tf_env/lib/python3.11/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "Predicting:  98%|█████████▊| 63/64 [03:42<00:02,  2.20s/combo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions for z_ret_invn_w_vw_mse saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 64/64 [03:43<00:00,  3.49s/combo]\n"
     ]
    }
   ],
   "source": [
    "# %% Phase 3: Define worker_predict with correct signature\n",
    "def worker_predict(combo, var, lbl, wt, loss, path, gpu_id):\n",
    "    out_path = pred_dir / f\"{combo}.parquet\"\n",
    "    if os.path.exists(out_path):\n",
    "        print(f\"[SKIP] dataset for {combo} already exists\")\n",
    "        return combo\n",
    "\n",
    "    device = f'/GPU:{gpu_id}' if gpu_id is not None else '/CPU:0'\n",
    "    with tf.device(device):\n",
    "        files = sorted(path.glob('run_*.keras'))\n",
    "        y_sum = None\n",
    "        for mf in files:\n",
    "            m = tf.keras.models.load_model(str(mf))\n",
    "            pred = m.predict(ds_feat[var], verbose=0).ravel()\n",
    "            y_sum = pred if y_sum is None else y_sum + pred\n",
    "            del m\n",
    "        y_hat = y_sum / len(files)\n",
    "\n",
    "    panel = truth_dfs[var].copy()\n",
    "    panel['signal'] = y_hat\n",
    "\n",
    "    panel.to_parquet(out_path, index=False)\n",
    "    tqdm.write(f\"predictions for {combo} saved.\")\n",
    "    del panel, y_sum, y_hat\n",
    "    gc.collect()\n",
    "    return combo\n",
    "\n",
    "\n",
    "# %% Phase 4: Run parallel predictions with tqdm using as_completed\n",
    "n_workers = 64\n",
    "with ThreadPoolExecutor(max_workers=n_workers) as exe:\n",
    "    futures = {exe.submit(worker_predict, *c): c[0] for c in combos}\n",
    "    for fut in tqdm(as_completed(futures),\n",
    "                    total=len(futures),\n",
    "                    desc=\"Predicting\",\n",
    "                    unit=\"combo\"):\n",
    "        fut.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d86bd4c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T23:35:31.716012Z",
     "start_time": "2025-05-08T23:35:02.366580Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing:   0%|          | 0/64 [00:00<?, ?combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:   2%|▏         | 1/64 [00:21<22:30, 21.43s/combo]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:   3%|▎         | 2/64 [00:23<10:07,  9.79s/combo]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:   8%|▊         | 5/64 [00:23<02:56,  2.99s/combo]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:   9%|▉         | 6/64 [00:24<02:11,  2.28s/combo]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  11%|█         | 7/64 [00:24<01:36,  1.70s/combo]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  12%|█▎        | 8/64 [00:24<01:16,  1.36s/combo]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  16%|█▌        | 10/64 [00:24<00:44,  1.22combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  19%|█▉        | 12/64 [00:25<00:27,  1.89combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  22%|██▏       | 14/64 [00:25<00:18,  2.65combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  27%|██▋       | 17/64 [00:25<00:11,  4.21combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  31%|███▏      | 20/64 [00:25<00:07,  5.94combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  34%|███▍      | 22/64 [00:25<00:06,  6.61combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  38%|███▊      | 24/64 [00:26<00:05,  7.53combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  44%|████▍     | 28/64 [00:26<00:03,  9.95combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  47%|████▋     | 30/64 [00:26<00:03, 10.48combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  52%|█████▏    | 33/64 [00:26<00:02, 13.19combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing:  61%|██████    | 39/64 [00:26<00:01, 20.41combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  69%|██████▉   | 44/64 [00:26<00:00, 25.15combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  83%|████████▎ | 53/64 [00:26<00:00, 38.04combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing:  97%|█████████▋| 62/64 [00:26<00:00, 49.48combo/s]/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "/tmp/ipykernel_687968/2473632056.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ics = df.groupby('eom').apply(\n",
      "Analyzing: 100%|██████████| 64/64 [00:27<00:00,  2.37combo/s]\n"
     ]
    }
   ],
   "source": [
    "# %% Phase 5: Define analysis helpers\n",
    "def construct_quantile_portfolios(df,\n",
    "                                  signal_col='signal',\n",
    "                                  date_col='eom',\n",
    "                                  weight_col='w',\n",
    "                                  return_col='y',\n",
    "                                  n=10):\n",
    "    df0 = df.dropna(\n",
    "        subset=[date_col, weight_col, return_col, signal_col]).copy()\n",
    "    df0['rank_pct'] = df0.groupby(date_col)[signal_col].rank(method='first',\n",
    "                                                             pct=True)\n",
    "    df0['quantile'] = np.ceil(df0['rank_pct'] * n).astype(int).clip(1, n)\n",
    "    df0['wR'] = df0[weight_col] * df0[return_col]\n",
    "    grp = df0.groupby([date_col, 'quantile'])\n",
    "    port = (grp['wR'].sum() / grp[weight_col].sum()).unstack(fill_value=np.nan)\n",
    "    port.columns = [f\"q{q}\" for q in port.columns]\n",
    "    port['long_short'] = port[f\"q{n}\"] - port[\"q1\"]\n",
    "    return port.sort_index()\n",
    "\n",
    "\n",
    "def evaluate_portfolios(returns, freq=12):\n",
    "    rets = returns.dropna(how='all')\n",
    "    mean_ret = rets.mean() * freq\n",
    "    vol = rets.std(ddof=1) * np.sqrt(freq)\n",
    "    sharpe = mean_ret / vol\n",
    "    wealth = (1 + rets).cumprod()\n",
    "    running_max = wealth.cummax()\n",
    "    drawdown = 1 - wealth / running_max\n",
    "    perf = pd.DataFrame({\n",
    "        'mean_return': mean_ret,\n",
    "        'vol': vol,\n",
    "        'sharpe': sharpe,\n",
    "        'max_drawdown': drawdown.max()\n",
    "    })\n",
    "    # transpose so index = portfolios, columns = metrics\n",
    "    return perf\n",
    "\n",
    "\n",
    "# %% Phase 6: Parallel analysis and Fama-MacBeth, using existing combos metadata\n",
    "y = 'y'\n",
    "def analyze_combo(args):\n",
    "    combo, var, lbl, wt, loss, path, gpu_id = args\n",
    "    file_path = pred_dir / f\"{combo}.parquet\"\n",
    "    # skip if file does not exist\n",
    "    if not file_path.exists():\n",
    "        tqdm.write(f\"[!] File not found, skipping combo: {combo}\")\n",
    "        return None\n",
    "    df = pd.read_parquet(file_path)\n",
    "    port = construct_quantile_portfolios(df)\n",
    "    perf = evaluate_portfolios(port)\n",
    "    result = {\n",
    "        'combo': combo,\n",
    "        'variant': var,\n",
    "        'label': lbl,\n",
    "        'weight': wt,\n",
    "        'loss': loss\n",
    "    }\n",
    "    # add sharpe metrics for each portfolio\n",
    "    for portfolio in perf.index:\n",
    "        result[f\"sharpe_{portfolio}\"] = perf.at[portfolio, 'sharpe']\n",
    "\n",
    "    # Fama-MacBeth regression\n",
    "    X = sm.add_constant(df['signal'])\n",
    "    regr = sm.OLS(df[y], X).fit()\n",
    "    result['fm_beta'] = regr.params.get('signal', np.nan)\n",
    "    result['fm_tstat'] = regr.tvalues.get('signal', np.nan)\n",
    "    ics = df.groupby('eom').apply(\n",
    "        lambda d: d['signal'].corr(d[y], method='spearman'))\n",
    "    result['ic_mean'] = ics.mean()\n",
    "    result['ic_tstat'] = ics.mean() / (\n",
    "        ics.std(ddof=1) / np.sqrt(ics.count())) if ics.count() > 1 else np.nan\n",
    "    return pd.DataFrame([result])\n",
    "\n",
    "\n",
    "# execute analysis in parallel with real-time updates\n",
    "stats = []\n",
    "n_workers = min(os.cpu_count() or 1, len(combos))\n",
    "with ThreadPoolExecutor(max_workers=n_workers) as exe:\n",
    "    futures = {exe.submit(analyze_combo, c): c[0] for c in combos}\n",
    "    for fut in tqdm(as_completed(futures),\n",
    "                    total=len(futures),\n",
    "                    desc=\"Analyzing\",\n",
    "                    unit=\"combo\"):\n",
    "        stats.append(fut.result())\n",
    "\n",
    "stats_df = pd.concat(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a26ccd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T23:35:33.584329Z",
     "start_time": "2025-05-08T23:35:33.580078Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_combo_performance_stats(\n",
    "        df: pd.DataFrame,\n",
    "        target: str = 'sharpe_long_short',\n",
    "        factors: list = ['variant', 'label', 'weight', 'loss'],\n",
    "        drop_first: bool = False):\n",
    "    \"\"\"\n",
    "    Fit an OLS regression via statsmodels to explain `target` by categorical `factors`,\n",
    "    providing intercept, coefficients, and significance levels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Panel data containing target and factor columns.\n",
    "    target : str\n",
    "        Name of the performance metric column.\n",
    "    factors : list of str\n",
    "        Categorical setup columns to dummy-encode.\n",
    "    drop_first : bool\n",
    "        If True, drop the first level of each factor to serve as baseline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : RegressionResultsWrapper\n",
    "        The fitted OLS model results; summary is printed.\n",
    "    \"\"\"\n",
    "    # Build design matrix\n",
    "    X = pd.get_dummies(df[factors], drop_first=drop_first)\n",
    "    #     X = sm.add_constant(X)  # always include intercept\n",
    "    y = df[target]\n",
    "\n",
    "    # Fit OLS\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def analyze_multiple_targets(df: pd.DataFrame,\n",
    "                             targets: list,\n",
    "                             factors: list = [\n",
    "                                 'variant', 'label', 'weight', 'loss'\n",
    "                             ],\n",
    "                             drop_first: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reuse analyze_combo_performance_stats to run regressions for multiple targets.\n",
    "    Returns a combined DataFrame of coefficients.\n",
    "    \"\"\"\n",
    "    all_coefs = []\n",
    "    for tgt in targets:\n",
    "        model = analyze_combo_performance_stats(df,\n",
    "                                                target=tgt,\n",
    "                                                factors=factors,\n",
    "                                                drop_first=drop_first)\n",
    "        params = model.params\n",
    "        all_coefs.append(pd.DataFrame(params, columns=[tgt]))\n",
    "\n",
    "    combined_df = pd.concat(all_coefs, axis=1)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0da626b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T23:32:26.474394Z",
     "start_time": "2025-05-08T23:32:26.461794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>variant</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "      <th>loss</th>\n",
       "      <th>sharpe_q1</th>\n",
       "      <th>sharpe_q2</th>\n",
       "      <th>sharpe_q3</th>\n",
       "      <th>sharpe_q4</th>\n",
       "      <th>sharpe_q5</th>\n",
       "      <th>sharpe_q6</th>\n",
       "      <th>sharpe_q7</th>\n",
       "      <th>sharpe_q8</th>\n",
       "      <th>sharpe_q9</th>\n",
       "      <th>sharpe_q10</th>\n",
       "      <th>sharpe_long_short</th>\n",
       "      <th>fm_beta</th>\n",
       "      <th>fm_tstat</th>\n",
       "      <th>ic_mean</th>\n",
       "      <th>ic_tstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_invn_w_ew_mse</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_invn</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.686743</td>\n",
       "      <td>0.648738</td>\n",
       "      <td>0.590922</td>\n",
       "      <td>0.656697</td>\n",
       "      <td>0.675330</td>\n",
       "      <td>0.588211</td>\n",
       "      <td>0.523123</td>\n",
       "      <td>0.437883</td>\n",
       "      <td>0.526845</td>\n",
       "      <td>0.485773</td>\n",
       "      <td>-0.106805</td>\n",
       "      <td>-0.010400</td>\n",
       "      <td>-1.461543</td>\n",
       "      <td>-0.037184</td>\n",
       "      <td>-8.061258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_exc_lead1m_w_vw_mse</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_exc_lead1m</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.665572</td>\n",
       "      <td>0.694707</td>\n",
       "      <td>0.757096</td>\n",
       "      <td>0.647091</td>\n",
       "      <td>0.581812</td>\n",
       "      <td>0.647773</td>\n",
       "      <td>0.631843</td>\n",
       "      <td>0.466140</td>\n",
       "      <td>0.423915</td>\n",
       "      <td>0.484591</td>\n",
       "      <td>-0.078327</td>\n",
       "      <td>-0.003613</td>\n",
       "      <td>-0.844821</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>-8.167034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_exc_lead1m_w_vw_mae</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_exc_lead1m</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.684165</td>\n",
       "      <td>0.656908</td>\n",
       "      <td>0.661541</td>\n",
       "      <td>0.704069</td>\n",
       "      <td>0.623348</td>\n",
       "      <td>0.674423</td>\n",
       "      <td>0.629423</td>\n",
       "      <td>0.659743</td>\n",
       "      <td>0.563962</td>\n",
       "      <td>0.639803</td>\n",
       "      <td>-0.073935</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.201893</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>3.425730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_z_w_vw_mae</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_z</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.600054</td>\n",
       "      <td>0.595727</td>\n",
       "      <td>0.556420</td>\n",
       "      <td>0.592107</td>\n",
       "      <td>0.578844</td>\n",
       "      <td>0.662676</td>\n",
       "      <td>0.695824</td>\n",
       "      <td>0.698431</td>\n",
       "      <td>0.678080</td>\n",
       "      <td>0.654568</td>\n",
       "      <td>-0.064103</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>-0.521399</td>\n",
       "      <td>-0.006987</td>\n",
       "      <td>-1.408658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_z_w_ew_mae</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_z</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.549303</td>\n",
       "      <td>0.486063</td>\n",
       "      <td>0.416587</td>\n",
       "      <td>0.453581</td>\n",
       "      <td>0.600676</td>\n",
       "      <td>0.658907</td>\n",
       "      <td>0.565615</td>\n",
       "      <td>0.716592</td>\n",
       "      <td>0.677718</td>\n",
       "      <td>-0.053891</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.157398</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>6.602181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invn_ret_exc_lead1m_w_vw_mse</td>\n",
       "      <td>invn</td>\n",
       "      <td>ret_exc_lead1m</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mse</td>\n",
       "      <td>-0.141662</td>\n",
       "      <td>0.392322</td>\n",
       "      <td>0.443622</td>\n",
       "      <td>0.535707</td>\n",
       "      <td>0.716958</td>\n",
       "      <td>0.669732</td>\n",
       "      <td>0.650764</td>\n",
       "      <td>0.713966</td>\n",
       "      <td>0.806157</td>\n",
       "      <td>0.725975</td>\n",
       "      <td>0.808348</td>\n",
       "      <td>0.376752</td>\n",
       "      <td>32.339828</td>\n",
       "      <td>0.075423</td>\n",
       "      <td>16.245264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invn_ret_pct_w_ew_mae</td>\n",
       "      <td>invn</td>\n",
       "      <td>ret_pct</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mae</td>\n",
       "      <td>-0.188175</td>\n",
       "      <td>0.242581</td>\n",
       "      <td>0.364825</td>\n",
       "      <td>0.530886</td>\n",
       "      <td>0.420746</td>\n",
       "      <td>0.585459</td>\n",
       "      <td>0.767559</td>\n",
       "      <td>0.687346</td>\n",
       "      <td>0.813079</td>\n",
       "      <td>0.654799</td>\n",
       "      <td>0.814882</td>\n",
       "      <td>0.089387</td>\n",
       "      <td>43.487326</td>\n",
       "      <td>0.083696</td>\n",
       "      <td>17.299266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invn_ret_pct_w_ew_mse</td>\n",
       "      <td>invn</td>\n",
       "      <td>ret_pct</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.091494</td>\n",
       "      <td>0.368122</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>0.528287</td>\n",
       "      <td>0.551235</td>\n",
       "      <td>0.614574</td>\n",
       "      <td>0.656754</td>\n",
       "      <td>0.816010</td>\n",
       "      <td>0.708010</td>\n",
       "      <td>0.884238</td>\n",
       "      <td>0.825277</td>\n",
       "      <td>0.206725</td>\n",
       "      <td>47.910817</td>\n",
       "      <td>0.077659</td>\n",
       "      <td>19.052041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invn_ret_invn_w_ew_mae</td>\n",
       "      <td>invn</td>\n",
       "      <td>ret_invn</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mae</td>\n",
       "      <td>-0.191661</td>\n",
       "      <td>0.263063</td>\n",
       "      <td>0.318381</td>\n",
       "      <td>0.423225</td>\n",
       "      <td>0.655178</td>\n",
       "      <td>0.524396</td>\n",
       "      <td>0.700297</td>\n",
       "      <td>0.738989</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.692117</td>\n",
       "      <td>0.893507</td>\n",
       "      <td>0.033318</td>\n",
       "      <td>45.192934</td>\n",
       "      <td>0.079802</td>\n",
       "      <td>17.827567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pct_ret_exc_lead1m_w_ew_mse</td>\n",
       "      <td>pct</td>\n",
       "      <td>ret_exc_lead1m</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mse</td>\n",
       "      <td>-0.103593</td>\n",
       "      <td>0.327296</td>\n",
       "      <td>0.580435</td>\n",
       "      <td>0.653214</td>\n",
       "      <td>0.807847</td>\n",
       "      <td>0.654125</td>\n",
       "      <td>0.702839</td>\n",
       "      <td>0.633478</td>\n",
       "      <td>0.667938</td>\n",
       "      <td>0.564799</td>\n",
       "      <td>1.122769</td>\n",
       "      <td>0.275848</td>\n",
       "      <td>44.774782</td>\n",
       "      <td>0.055182</td>\n",
       "      <td>14.550152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           combo variant           label weight loss  \\\n",
       "0          raw_ret_invn_w_ew_mse     raw        ret_invn   w_ew  mse   \n",
       "0    raw_ret_exc_lead1m_w_vw_mse     raw  ret_exc_lead1m   w_vw  mse   \n",
       "0    raw_ret_exc_lead1m_w_vw_mae     raw  ret_exc_lead1m   w_vw  mae   \n",
       "0             raw_ret_z_w_vw_mae     raw           ret_z   w_vw  mae   \n",
       "0             raw_ret_z_w_ew_mae     raw           ret_z   w_ew  mae   \n",
       "..                           ...     ...             ...    ...  ...   \n",
       "0   invn_ret_exc_lead1m_w_vw_mse    invn  ret_exc_lead1m   w_vw  mse   \n",
       "0          invn_ret_pct_w_ew_mae    invn         ret_pct   w_ew  mae   \n",
       "0          invn_ret_pct_w_ew_mse    invn         ret_pct   w_ew  mse   \n",
       "0         invn_ret_invn_w_ew_mae    invn        ret_invn   w_ew  mae   \n",
       "0    pct_ret_exc_lead1m_w_ew_mse     pct  ret_exc_lead1m   w_ew  mse   \n",
       "\n",
       "    sharpe_q1  sharpe_q2  sharpe_q3  sharpe_q4  sharpe_q5  sharpe_q6  \\\n",
       "0    0.686743   0.648738   0.590922   0.656697   0.675330   0.588211   \n",
       "0    0.665572   0.694707   0.757096   0.647091   0.581812   0.647773   \n",
       "0    0.684165   0.656908   0.661541   0.704069   0.623348   0.674423   \n",
       "0    0.600054   0.595727   0.556420   0.592107   0.578844   0.662676   \n",
       "0    0.593985   0.549303   0.486063   0.416587   0.453581   0.600676   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "0   -0.141662   0.392322   0.443622   0.535707   0.716958   0.669732   \n",
       "0   -0.188175   0.242581   0.364825   0.530886   0.420746   0.585459   \n",
       "0    0.091494   0.368122   0.386784   0.528287   0.551235   0.614574   \n",
       "0   -0.191661   0.263063   0.318381   0.423225   0.655178   0.524396   \n",
       "0   -0.103593   0.327296   0.580435   0.653214   0.807847   0.654125   \n",
       "\n",
       "    sharpe_q7  sharpe_q8  sharpe_q9  sharpe_q10  sharpe_long_short   fm_beta  \\\n",
       "0    0.523123   0.437883   0.526845    0.485773          -0.106805 -0.010400   \n",
       "0    0.631843   0.466140   0.423915    0.484591          -0.078327 -0.003613   \n",
       "0    0.629423   0.659743   0.563962    0.639803          -0.073935  0.002158   \n",
       "0    0.695824   0.698431   0.678080    0.654568          -0.064103 -0.001011   \n",
       "0    0.658907   0.565615   0.716592    0.677718          -0.053891  0.001762   \n",
       "..        ...        ...        ...         ...                ...       ...   \n",
       "0    0.650764   0.713966   0.806157    0.725975           0.808348  0.376752   \n",
       "0    0.767559   0.687346   0.813079    0.654799           0.814882  0.089387   \n",
       "0    0.656754   0.816010   0.708010    0.884238           0.825277  0.206725   \n",
       "0    0.700297   0.738989   0.765690    0.692117           0.893507  0.033318   \n",
       "0    0.702839   0.633478   0.667938    0.564799           1.122769  0.275848   \n",
       "\n",
       "     fm_tstat   ic_mean   ic_tstat  \n",
       "0   -1.461543 -0.037184  -8.061258  \n",
       "0   -0.844821 -0.037501  -8.167034  \n",
       "0    0.201893  0.008812   3.425730  \n",
       "0   -0.521399 -0.006987  -1.408658  \n",
       "0    0.157398  0.026513   6.602181  \n",
       "..        ...       ...        ...  \n",
       "0   32.339828  0.075423  16.245264  \n",
       "0   43.487326  0.083696  17.299266  \n",
       "0   47.910817  0.077659  19.052041  \n",
       "0   45.192934  0.079802  17.827567  \n",
       "0   44.774782  0.055182  14.550152  \n",
       "\n",
       "[64 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.sort_values(['sharpe_long_short'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c14a9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T01:02:45.048762Z",
     "start_time": "2025-05-09T01:02:45.036496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>variant</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "      <th>loss</th>\n",
       "      <th>sharpe_q1</th>\n",
       "      <th>sharpe_q2</th>\n",
       "      <th>sharpe_q3</th>\n",
       "      <th>sharpe_q4</th>\n",
       "      <th>sharpe_q5</th>\n",
       "      <th>sharpe_q6</th>\n",
       "      <th>sharpe_q7</th>\n",
       "      <th>sharpe_q8</th>\n",
       "      <th>sharpe_q9</th>\n",
       "      <th>sharpe_q10</th>\n",
       "      <th>sharpe_long_short</th>\n",
       "      <th>fm_beta</th>\n",
       "      <th>fm_tstat</th>\n",
       "      <th>ic_mean</th>\n",
       "      <th>ic_tstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_exc_lead1m_w_vw_mse</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_exc_lead1m</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.657299</td>\n",
       "      <td>0.570377</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>0.699272</td>\n",
       "      <td>0.536405</td>\n",
       "      <td>0.572740</td>\n",
       "      <td>0.706519</td>\n",
       "      <td>0.669869</td>\n",
       "      <td>0.640574</td>\n",
       "      <td>0.645546</td>\n",
       "      <td>-0.010784</td>\n",
       "      <td>-0.010637</td>\n",
       "      <td>-0.432395</td>\n",
       "      <td>-0.028671</td>\n",
       "      <td>-5.481941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_exc_lead1m_w_ew_mse</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_exc_lead1m</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.576724</td>\n",
       "      <td>0.599126</td>\n",
       "      <td>0.606013</td>\n",
       "      <td>0.635964</td>\n",
       "      <td>0.497792</td>\n",
       "      <td>0.465906</td>\n",
       "      <td>0.720788</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.644442</td>\n",
       "      <td>0.661653</td>\n",
       "      <td>0.082425</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>0.541704</td>\n",
       "      <td>-0.015769</td>\n",
       "      <td>-3.152833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_z_w_vw_mse</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_z</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.628786</td>\n",
       "      <td>0.555368</td>\n",
       "      <td>0.656153</td>\n",
       "      <td>0.548955</td>\n",
       "      <td>0.676968</td>\n",
       "      <td>0.567339</td>\n",
       "      <td>0.685074</td>\n",
       "      <td>0.653190</td>\n",
       "      <td>0.738782</td>\n",
       "      <td>0.650284</td>\n",
       "      <td>0.036685</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.517661</td>\n",
       "      <td>-0.013291</td>\n",
       "      <td>-4.102083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_z_w_ew_mse</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_z</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.677612</td>\n",
       "      <td>0.609888</td>\n",
       "      <td>0.646657</td>\n",
       "      <td>0.543687</td>\n",
       "      <td>0.657027</td>\n",
       "      <td>0.638752</td>\n",
       "      <td>0.658967</td>\n",
       "      <td>0.519706</td>\n",
       "      <td>0.463544</td>\n",
       "      <td>0.428343</td>\n",
       "      <td>-0.109347</td>\n",
       "      <td>-0.034720</td>\n",
       "      <td>-0.753256</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>-1.761939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw_ret_pct_w_vw_mae</td>\n",
       "      <td>raw</td>\n",
       "      <td>ret_pct</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.699676</td>\n",
       "      <td>0.515996</td>\n",
       "      <td>0.571950</td>\n",
       "      <td>0.464046</td>\n",
       "      <td>0.446460</td>\n",
       "      <td>0.531143</td>\n",
       "      <td>0.677634</td>\n",
       "      <td>0.722518</td>\n",
       "      <td>0.602211</td>\n",
       "      <td>0.750887</td>\n",
       "      <td>0.256096</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.524100</td>\n",
       "      <td>-0.006453</td>\n",
       "      <td>-4.037856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pct_ret_invn_w_vw_mse</td>\n",
       "      <td>pct</td>\n",
       "      <td>ret_invn</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.034941</td>\n",
       "      <td>0.252694</td>\n",
       "      <td>0.342422</td>\n",
       "      <td>0.424254</td>\n",
       "      <td>0.557752</td>\n",
       "      <td>0.679340</td>\n",
       "      <td>0.565011</td>\n",
       "      <td>0.614576</td>\n",
       "      <td>0.750385</td>\n",
       "      <td>0.772897</td>\n",
       "      <td>0.529557</td>\n",
       "      <td>0.043685</td>\n",
       "      <td>28.791242</td>\n",
       "      <td>0.094355</td>\n",
       "      <td>13.671888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invn_ret_exc_lead1m_w_vw_mae</td>\n",
       "      <td>invn</td>\n",
       "      <td>ret_exc_lead1m</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mae</td>\n",
       "      <td>-0.068922</td>\n",
       "      <td>0.148611</td>\n",
       "      <td>0.365403</td>\n",
       "      <td>0.375545</td>\n",
       "      <td>0.631527</td>\n",
       "      <td>0.550076</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.710235</td>\n",
       "      <td>0.658853</td>\n",
       "      <td>0.848560</td>\n",
       "      <td>0.630544</td>\n",
       "      <td>0.334580</td>\n",
       "      <td>29.638486</td>\n",
       "      <td>0.094492</td>\n",
       "      <td>13.709032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invn_ret_pct_w_ew_mse</td>\n",
       "      <td>invn</td>\n",
       "      <td>ret_pct</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mse</td>\n",
       "      <td>-0.242620</td>\n",
       "      <td>0.173203</td>\n",
       "      <td>0.295554</td>\n",
       "      <td>0.387761</td>\n",
       "      <td>0.470061</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>0.565711</td>\n",
       "      <td>0.703529</td>\n",
       "      <td>0.868473</td>\n",
       "      <td>0.816100</td>\n",
       "      <td>0.800725</td>\n",
       "      <td>0.175873</td>\n",
       "      <td>44.222812</td>\n",
       "      <td>0.094542</td>\n",
       "      <td>15.988462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invn_ret_invn_w_vw_mae</td>\n",
       "      <td>invn</td>\n",
       "      <td>ret_invn</td>\n",
       "      <td>w_vw</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.269911</td>\n",
       "      <td>0.329039</td>\n",
       "      <td>0.333533</td>\n",
       "      <td>0.574759</td>\n",
       "      <td>0.552210</td>\n",
       "      <td>0.582295</td>\n",
       "      <td>0.635120</td>\n",
       "      <td>0.630831</td>\n",
       "      <td>0.847835</td>\n",
       "      <td>0.501736</td>\n",
       "      <td>0.029979</td>\n",
       "      <td>25.862589</td>\n",
       "      <td>0.094563</td>\n",
       "      <td>12.863858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pct_ret_z_w_ew_mae</td>\n",
       "      <td>pct</td>\n",
       "      <td>ret_z</td>\n",
       "      <td>w_ew</td>\n",
       "      <td>mae</td>\n",
       "      <td>-0.150045</td>\n",
       "      <td>0.127443</td>\n",
       "      <td>0.257170</td>\n",
       "      <td>0.322301</td>\n",
       "      <td>0.408795</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>0.561028</td>\n",
       "      <td>0.621786</td>\n",
       "      <td>0.783128</td>\n",
       "      <td>0.905946</td>\n",
       "      <td>0.666996</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>38.768703</td>\n",
       "      <td>0.095289</td>\n",
       "      <td>15.549504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           combo variant           label weight loss  \\\n",
       "0    raw_ret_exc_lead1m_w_vw_mse     raw  ret_exc_lead1m   w_vw  mse   \n",
       "0    raw_ret_exc_lead1m_w_ew_mse     raw  ret_exc_lead1m   w_ew  mse   \n",
       "0             raw_ret_z_w_vw_mse     raw           ret_z   w_vw  mse   \n",
       "0             raw_ret_z_w_ew_mse     raw           ret_z   w_ew  mse   \n",
       "0           raw_ret_pct_w_vw_mae     raw         ret_pct   w_vw  mae   \n",
       "..                           ...     ...             ...    ...  ...   \n",
       "0          pct_ret_invn_w_vw_mse     pct        ret_invn   w_vw  mse   \n",
       "0   invn_ret_exc_lead1m_w_vw_mae    invn  ret_exc_lead1m   w_vw  mae   \n",
       "0          invn_ret_pct_w_ew_mse    invn         ret_pct   w_ew  mse   \n",
       "0         invn_ret_invn_w_vw_mae    invn        ret_invn   w_vw  mae   \n",
       "0             pct_ret_z_w_ew_mae     pct           ret_z   w_ew  mae   \n",
       "\n",
       "    sharpe_q1  sharpe_q2  sharpe_q3  sharpe_q4  sharpe_q5  sharpe_q6  \\\n",
       "0    0.657299   0.570377   0.575231   0.699272   0.536405   0.572740   \n",
       "0    0.576724   0.599126   0.606013   0.635964   0.497792   0.465906   \n",
       "0    0.628786   0.555368   0.656153   0.548955   0.676968   0.567339   \n",
       "0    0.677612   0.609888   0.646657   0.543687   0.657027   0.638752   \n",
       "0    0.699676   0.515996   0.571950   0.464046   0.446460   0.531143   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "0    0.034941   0.252694   0.342422   0.424254   0.557752   0.679340   \n",
       "0   -0.068922   0.148611   0.365403   0.375545   0.631527   0.550076   \n",
       "0   -0.242620   0.173203   0.295554   0.387761   0.470061   0.535879   \n",
       "0    0.008168   0.269911   0.329039   0.333533   0.574759   0.552210   \n",
       "0   -0.150045   0.127443   0.257170   0.322301   0.408795   0.491876   \n",
       "\n",
       "    sharpe_q7  sharpe_q8  sharpe_q9  sharpe_q10  sharpe_long_short   fm_beta  \\\n",
       "0    0.706519   0.669869   0.640574    0.645546          -0.010784 -0.010637   \n",
       "0    0.720788   0.380435   0.644442    0.661653           0.082425  0.011522   \n",
       "0    0.685074   0.653190   0.738782    0.650284           0.036685  0.001373   \n",
       "0    0.658967   0.519706   0.463544    0.428343          -0.109347 -0.034720   \n",
       "0    0.677634   0.722518   0.602211    0.750887           0.256096  0.000316   \n",
       "..        ...        ...        ...         ...                ...       ...   \n",
       "0    0.565011   0.614576   0.750385    0.772897           0.529557  0.043685   \n",
       "0    0.533744   0.710235   0.658853    0.848560           0.630544  0.334580   \n",
       "0    0.565711   0.703529   0.868473    0.816100           0.800725  0.175873   \n",
       "0    0.582295   0.635120   0.630831    0.847835           0.501736  0.029979   \n",
       "0    0.561028   0.621786   0.783128    0.905946           0.666996  0.054652   \n",
       "\n",
       "     fm_tstat   ic_mean   ic_tstat  \n",
       "0   -0.432395 -0.028671  -5.481941  \n",
       "0    0.541704 -0.015769  -3.152833  \n",
       "0    0.517661 -0.013291  -4.102083  \n",
       "0   -0.753256 -0.006907  -1.761939  \n",
       "0    0.524100 -0.006453  -4.037856  \n",
       "..        ...       ...        ...  \n",
       "0   28.791242  0.094355  13.671888  \n",
       "0   29.638486  0.094492  13.709032  \n",
       "0   44.222812  0.094542  15.988462  \n",
       "0   25.862589  0.094563  12.863858  \n",
       "0   38.768703  0.095289  15.549504  \n",
       "\n",
       "[64 rows x 20 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.sort_values(['ic_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9dab12c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T23:32:28.236134Z",
     "start_time": "2025-05-08T23:32:28.216792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sharpe_long_short</th>\n",
       "      <th>fm_beta</th>\n",
       "      <th>fm_tstat</th>\n",
       "      <th>ic_mean</th>\n",
       "      <th>ic_tstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label_ret_exc_lead1m</th>\n",
       "      <td>0.074676</td>\n",
       "      <td>0.144481</td>\n",
       "      <td>4.168051</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.229203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_ret_invn</th>\n",
       "      <td>0.104666</td>\n",
       "      <td>-0.049404</td>\n",
       "      <td>5.023420</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>2.718069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_ret_pct</th>\n",
       "      <td>0.070676</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>2.483542</td>\n",
       "      <td>0.016498</td>\n",
       "      <td>2.997093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_ret_z</th>\n",
       "      <td>0.052253</td>\n",
       "      <td>-0.033559</td>\n",
       "      <td>5.609942</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>1.749497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_mae</th>\n",
       "      <td>0.180818</td>\n",
       "      <td>0.024803</td>\n",
       "      <td>7.881086</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>4.230748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_mse</th>\n",
       "      <td>0.121454</td>\n",
       "      <td>0.039124</td>\n",
       "      <td>9.403869</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>3.004708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_invn</th>\n",
       "      <td>0.268075</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>14.216500</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>5.104869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_pct</th>\n",
       "      <td>0.253982</td>\n",
       "      <td>0.041320</td>\n",
       "      <td>11.080081</td>\n",
       "      <td>0.026012</td>\n",
       "      <td>4.437554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_raw</th>\n",
       "      <td>-0.361932</td>\n",
       "      <td>-0.081489</td>\n",
       "      <td>-21.849422</td>\n",
       "      <td>-0.044883</td>\n",
       "      <td>-7.868940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_z</th>\n",
       "      <td>0.142147</td>\n",
       "      <td>0.061990</td>\n",
       "      <td>13.837797</td>\n",
       "      <td>0.028487</td>\n",
       "      <td>5.561974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_w_ew</th>\n",
       "      <td>0.228264</td>\n",
       "      <td>0.036374</td>\n",
       "      <td>14.614072</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>4.503186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_w_vw</th>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.027553</td>\n",
       "      <td>2.670883</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>2.732271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sharpe_long_short   fm_beta   fm_tstat   ic_mean  \\\n",
       "label_ret_exc_lead1m           0.074676  0.144481   4.168051 -0.001108   \n",
       "label_ret_invn                 0.104666 -0.049404   5.023420  0.016288   \n",
       "label_ret_pct                  0.070676  0.002409   2.483542  0.016498   \n",
       "label_ret_z                    0.052253 -0.033559   5.609942  0.005746   \n",
       "loss_mae                       0.180818  0.024803   7.881086  0.026120   \n",
       "loss_mse                       0.121454  0.039124   9.403869  0.011305   \n",
       "variant_invn                   0.268075  0.042105  14.216500  0.027809   \n",
       "variant_pct                    0.253982  0.041320  11.080081  0.026012   \n",
       "variant_raw                   -0.361932 -0.081489 -21.849422 -0.044883   \n",
       "variant_z                      0.142147  0.061990  13.837797  0.028487   \n",
       "weight_w_ew                    0.228264  0.036374  14.614072  0.014944   \n",
       "weight_w_vw                    0.074008  0.027553   2.670883  0.022481   \n",
       "\n",
       "                      ic_tstat  \n",
       "label_ret_exc_lead1m -0.229203  \n",
       "label_ret_invn        2.718069  \n",
       "label_ret_pct         2.997093  \n",
       "label_ret_z           1.749497  \n",
       "loss_mae              4.230748  \n",
       "loss_mse              3.004708  \n",
       "variant_invn          5.104869  \n",
       "variant_pct           4.437554  \n",
       "variant_raw          -7.868940  \n",
       "variant_z             5.561974  \n",
       "weight_w_ew           4.503186  \n",
       "weight_w_vw           2.732271  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_multiple_targets(\n",
    "    stats_df,\n",
    "    ['sharpe_long_short', 'fm_beta', 'fm_tstat', 'ic_mean', 'ic_tstat']).sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
