{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcea3641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:40:20.137687Z",
     "start_time": "2025-05-06T11:39:35.694543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 07:39:36.222915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746531576.240507 1686425 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746531576.246176 1686425 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746531576.264015 1686425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746531576.264058 1686425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746531576.264060 1686425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746531576.264061 1686425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-06 07:39:36.269591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Paths (single source of truth)\n",
    "DATA_DIR = os.environ.get('DATA_DIR',\n",
    "                          '/gpfs/home/zh283/StockPredictionDNN/Data')\n",
    "PARQUET_DIR = os.path.join(DATA_DIR, 'parquet')\n",
    "FACTOR_XLSX = os.path.join(DATA_DIR, 'factors_list.xlsx')\n",
    "TFRECORD_DIR = os.path.join(DATA_DIR, 'tfrecords')\n",
    "\n",
    "# Cleanup\n",
    "if os.path.exists(TFRECORD_DIR):\n",
    "    shutil.rmtree(TFRECORD_DIR)\n",
    "os.makedirs(TFRECORD_DIR, exist_ok=True)\n",
    "\n",
    "# Feature & schema\n",
    "chars = pd.read_excel(FACTOR_XLSX)\n",
    "FEATURE_COLS = chars.loc[chars['abr_jkp'].notna(), 'abr_jkp'].tolist()\n",
    "META_COLS = [\n",
    "    'permno', 'eom', 'me', 'size_grp', 'crsp_exchcd', 'ret', 'ret_exc'\n",
    "]\n",
    "WEIGHT_COLS = ['w_ew', 'w_vw']\n",
    "LABEL_COLS = ['ret_exc_lead1m', 'ret_pct', 'ret_z', 'ret_invn']\n",
    "\n",
    "\n",
    "def _float_feature(v):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=v))\n",
    "\n",
    "\n",
    "def _int64_feature(v):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=v))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def serialize_example(rec):\n",
    "    features = {}\n",
    "    # Pack vector\n",
    "    features['feat'] = _float_feature([rec[c] for c in FEATURE_COLS])\n",
    "    # Pack scalars\n",
    "    for col in META_COLS + WEIGHT_COLS + LABEL_COLS:\n",
    "        val = rec[col]\n",
    "        if isinstance(val, str):\n",
    "            # e.g. 'size_grp' might be a categorical string\n",
    "            features[col] = _bytes_feature(val.encode('utf-8'))\n",
    "\n",
    "        elif isinstance(val, int):\n",
    "            features[col] = _int64_feature([val])\n",
    "        else:\n",
    "            features[col] = _float_feature([float(val)])\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features)) \\\n",
    "               .SerializeToString()\n",
    "\n",
    "\n",
    "def write_variant_year(args):\n",
    "    parquet_file, variant, out_dir = args\n",
    "    # derive year from folder name \"year=YYYY\"\n",
    "    year = os.path.basename(os.path.dirname(parquet_file)).split('=')[1]\n",
    "    shard_path = os.path.join(out_dir, f\"{variant}-year{year}.tfrecord\")\n",
    "    writer = tf.io.TFRecordWriter(shard_path)\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    for _, row in df.iterrows():\n",
    "        writer.write(serialize_example(row.to_dict()))\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    variants = ['raw', 'pct', 'z', 'invn']\n",
    "    tasks = []\n",
    "\n",
    "    # Create one subfolder per variant\n",
    "    for variant in variants:\n",
    "        variant_out = os.path.join(TFRECORD_DIR, variant)\n",
    "        os.makedirs(variant_out, exist_ok=True)\n",
    "\n",
    "        pattern = os.path.join(PARQUET_DIR, variant, 'year=*', '*.parquet')\n",
    "        for pf in glob.glob(pattern, recursive=True):\n",
    "            tasks.append((pf, variant, variant_out))\n",
    "\n",
    "    # Use up to one worker per task or per core\n",
    "    workers = min(len(tasks), cpu_count())\n",
    "    with Pool(processes=workers) as pool:\n",
    "        pool.map(write_variant_year, tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
